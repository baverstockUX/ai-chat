---
phase: 05-resources-management-and-sharing
plan: 06
type: execute
wave: 3
depends_on: [05-02]
files_modified:
  - lib/integrations/search/duckduckgo.ts
  - app/api/search/route.ts
  - components/chat/message-input.tsx
  - components/chat/image-uploader.tsx
  - app/api/chat/route.ts
autonomous: true

must_haves:
  truths:
    - "User can upload images in chat interface"
    - "Uploaded images display inline in conversation"
    - "AI can analyze uploaded images and respond about their content"
    - "User can trigger web search from chat"
    - "AI incorporates web search results into responses"
  artifacts:
    - path: "lib/integrations/search/duckduckgo.ts"
      provides: "Web search integration"
      exports: ["searchWeb"]
    - path: "app/api/search/route.ts"
      provides: "Search API endpoint"
      min_lines: 40
    - path: "components/chat/image-uploader.tsx"
      provides: "Image upload UI component"
      min_lines: 60
    - path: "components/chat/message-input.tsx"
      provides: "Enhanced message input with image support"
  key_links:
    - from: "message-input"
      to: "uploadImage"
      via: "FormData submission"
      pattern: "uploadImage.*FormData"
    - from: "chat API"
      to: "searchWeb"
      via: "search intent detection"
      pattern: "searchWeb.*query"
---

<objective>
Integrate multimodal input (image upload) and web search into chat interface, enabling users to attach images and have AI search for external information.

Purpose: Complete INPUT requirements (INPUT-01 through INPUT-06) with research Pattern 5 (image upload) and Pattern 6 (web search). Enhances chat with external knowledge.

Output: DuckDuckGo search integration, search API route, image uploader component, enhanced message input, and AI context injection.
</objective>

<execution_context>
@/Users/christian.baverstock/.claude/get-shit-done/workflows/execute-plan.md
@/Users/christian.baverstock/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-resources-management-and-sharing/05-RESEARCH.md
@.planning/phases/05-resources-management-and-sharing/05-02-SUMMARY.md
@.planning/phases/01-chat-foundation-authentication/01-04-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create web search integration</name>
  <files>lib/integrations/search/duckduckgo.ts, app/api/search/route.ts</files>
  <action>
1. Create DuckDuckGo search integration following research Pattern 6:

lib/integrations/search/duckduckgo.ts:
```typescript
interface SearchResult {
  title: string;
  url: string;
  snippet: string;
  source: string;
}

export async function searchWeb(query: string): Promise<SearchResult[]> {
  try {
    // DuckDuckGo Instant Answer API (free, no API key)
    const response = await fetch(
      `https://api.duckduckgo.com/?q=${encodeURIComponent(query)}&format=json&no_redirect=1`,
      {
        headers: {
          'User-Agent': 'Mozilla/5.0 (compatible; AIChat/1.0)',
        },
      }
    );

    if (!response.ok) {
      throw new Error(`Search failed: ${response.statusText}`);
    }

    const data = await response.json();
    const results: SearchResult[] = [];

    // RelatedTopics contain search results
    if (data.RelatedTopics && Array.isArray(data.RelatedTopics)) {
      for (const topic of data.RelatedTopics) {
        if (topic.FirstURL && topic.Text) {
          results.push({
            title: topic.Text.split(' - ')[0] || topic.Text,
            url: topic.FirstURL,
            snippet: topic.Text,
            source: 'DuckDuckGo',
          });
        }
      }
    }

    // Abstract contains featured snippet
    if (data.Abstract) {
      results.unshift({
        title: data.Heading || 'Featured Result',
        url: data.AbstractURL || '',
        snippet: data.Abstract,
        source: 'DuckDuckGo',
      });
    }

    return results.slice(0, 5); // Top 5 results
  } catch (error) {
    console.error('Web search error:', error);
    return [];
  }
}
```

2. Create search API route:

app/api/search/route.ts:
```typescript
import { auth } from '@/app/(auth)/auth';
import { searchWeb } from '@/lib/integrations/search/duckduckgo';
import { NextResponse } from 'next/server';

export async function POST(req: Request) {
  const session = await auth();
  if (!session?.user?.id) {
    return new Response('Unauthorized', { status: 401 });
  }

  const { query } = await req.json();

  if (!query || query.length < 3) {
    return NextResponse.json(
      { error: 'Query must be at least 3 characters' },
      { status: 400 }
    );
  }

  try {
    const results = await searchWeb(query);

    // Format results for AI context injection
    const contextPrompt = results.length > 0
      ? `Web search results for "${query}":\n\n${results
          .map((r, i) => `[${i + 1}] ${r.title}\n${r.snippet}\nURL: ${r.url}`)
          .join('\n\n')}`
      : `No web search results found for "${query}"`;

    return NextResponse.json({
      results,
      contextPrompt,
    });
  } catch (error) {
    console.error('Search error:', error);
    return NextResponse.json(
      { error: 'Search failed' },
      { status: 500 }
    );
  }
}
```

Uses DuckDuckGo Instant Answer API (free, no key required).
  </action>
  <verify>
grep -A 50 "export async function searchWeb" lib/integrations/search/duckduckgo.ts
grep -A 40 "export async function POST" app/api/search/route.ts
grep "contextPrompt" app/api/search/route.ts
  </verify>
  <done>DuckDuckGo search integration and API route with context formatting</done>
</task>

<task type="auto">
  <name>Task 2: Create image uploader component</name>
  <files>components/chat/image-uploader.tsx</files>
  <action>
Create ImageUploader component following research code example:

components/chat/image-uploader.tsx:
```typescript
'use client';

import { useState, useRef } from 'react';
import { Button } from '@/components/ui/button';
import { uploadImage } from '@/app/(chat)/actions';
import { toast } from 'sonner';
import { Image as ImageIcon, X } from 'lucide-react';

interface ImageUploaderProps {
  onImageUploaded: (imageUrl: string) => void;
}

export function ImageUploader({ onImageUploaded }: ImageUploaderProps) {
  const [uploading, setUploading] = useState(false);
  const [preview, setPreview] = useState<string | null>(null);
  const [selectedFile, setSelectedFile] = useState<File | null>(null);
  const fileInputRef = useRef<HTMLInputElement>(null);

  const handleFileSelect = (e: React.ChangeEvent<HTMLInputElement>) => {
    const file = e.target.files?.[0];
    if (!file) return;

    // Validate file size (10MB)
    if (file.size > 10 * 1024 * 1024) {
      toast.error('File too large. Maximum size: 10MB');
      return;
    }

    // Validate file type
    const allowedTypes = ['image/jpeg', 'image/png', 'image/gif', 'image/webp'];
    if (!allowedTypes.includes(file.type)) {
      toast.error('Invalid file type. Allowed: JPEG, PNG, GIF, WebP');
      return;
    }

    setSelectedFile(file);

    // Show preview
    const reader = new FileReader();
    reader.onload = (e) => {
      setPreview(e.target?.result as string);
    };
    reader.readAsDataURL(file);
  };

  const handleUpload = async () => {
    if (!selectedFile) return;

    setUploading(true);
    try {
      const formData = new FormData();
      formData.append('image', selectedFile);

      const result = await uploadImage(formData);

      if (result.success && result.imageUrl) {
        onImageUploaded(result.imageUrl);
        toast.success('Image uploaded');
        handleClear();
      } else {
        toast.error(result.error || 'Upload failed');
      }
    } catch (error) {
      console.error('Upload error:', error);
      toast.error('Failed to upload image');
    } finally {
      setUploading(false);
    }
  };

  const handleClear = () => {
    setPreview(null);
    setSelectedFile(null);
    if (fileInputRef.current) {
      fileInputRef.current.value = '';
    }
  };

  return (
    <div className="space-y-2">
      <input
        ref={fileInputRef}
        type="file"
        accept="image/jpeg,image/png,image/gif,image/webp"
        onChange={handleFileSelect}
        className="hidden"
      />

      {!preview ? (
        <Button
          type="button"
          variant="outline"
          size="sm"
          onClick={() => fileInputRef.current?.click()}
        >
          <ImageIcon className="h-4 w-4 mr-2" />
          Add Image
        </Button>
      ) : (
        <div className="relative inline-block">
          <img
            src={preview}
            alt="Preview"
            className="max-w-[200px] h-auto max-h-32 rounded border"
          />
          <Button
            type="button"
            variant="ghost"
            size="icon"
            className="absolute top-1 right-1 h-6 w-6 bg-background/80"
            onClick={handleClear}
          >
            <X className="h-4 w-4" />
          </Button>
          <Button
            type="button"
            onClick={handleUpload}
            disabled={uploading}
            size="sm"
            className="mt-2"
          >
            {uploading ? 'Uploading...' : 'Upload Image'}
          </Button>
        </div>
      )}
    </div>
  );
}
```

Uses FileReader for preview, validates client-side before upload, shows thumbnail with remove button.
  </action>
  <verify>
grep -A 80 "export function ImageUploader" components/chat/image-uploader.tsx
grep "FileReader" components/chat/image-uploader.tsx
grep "max-w-\[200px\]" components/chat/image-uploader.tsx
  </verify>
  <done>ImageUploader component with preview, validation, and upload</done>
</task>

<task type="auto">
  <name>Task 3: Integrate image upload and search into chat</name>
  <files>components/chat/message-input.tsx, app/api/chat/route.ts</files>
  <action>
1. Update MessageInput to support image uploads:

In components/chat/message-input.tsx (or create if doesn't exist):
```typescript
'use client';

import { useState } from 'react';
import { Textarea } from '@/components/ui/textarea';
import { Button } from '@/components/ui/button';
import { ImageUploader } from './image-uploader';
import { Send } from 'lucide-react';

interface MessageInputProps {
  onSend: (message: string, imageUrl?: string) => void;
  disabled?: boolean;
}

export function MessageInput({ onSend, disabled }: MessageInputProps) {
  const [message, setMessage] = useState('');
  const [attachedImage, setAttachedImage] = useState<string>('');

  const handleSend = () => {
    if (!message.trim() && !attachedImage) return;

    onSend(message, attachedImage || undefined);
    setMessage('');
    setAttachedImage('');
  };

  const handleKeyDown = (e: React.KeyboardEvent) => {
    if (e.key === 'Enter' && !e.shiftKey) {
      e.preventDefault();
      handleSend();
    }
  };

  return (
    <div className="space-y-2">
      {attachedImage && (
        <div className="relative inline-block">
          <img
            src={attachedImage}
            alt="Attached"
            className="max-w-[150px] h-auto max-h-24 rounded border"
          />
        </div>
      )}

      <div className="flex gap-2">
        <Textarea
          value={message}
          onChange={(e) => setMessage(e.target.value)}
          onKeyDown={handleKeyDown}
          placeholder="Type a message... (Shift+Enter for new line)"
          disabled={disabled}
          rows={3}
        />
      </div>

      <div className="flex items-center justify-between">
        <ImageUploader onImageUploaded={setAttachedImage} />

        <Button
          onClick={handleSend}
          disabled={disabled || (!message.trim() && !attachedImage)}
        >
          <Send className="h-4 w-4 mr-2" />
          Send
        </Button>
      </div>
    </div>
  );
}
```

2. Update chat API to handle search intent, image attachments, and multimodal AI messages:

In app/api/chat/route.ts, add:
- Search detection and context injection
- Message creation with attachments field populated from imageUrl
- Multimodal message format for AI model (text + image attachments)

```typescript
// Detect search intent from user message
const userMessage = messages[messages.length - 1]?.content || '';
const imageUrl = messages[messages.length - 1]?.imageUrl; // From MessageInput
let searchContext = '';

if (userMessage.toLowerCase().includes('search for') ||
    userMessage.toLowerCase().includes('look up') ||
    userMessage.toLowerCase().startsWith('search:')) {
  // Extract search query
  const searchMatch = userMessage.match(/search (?:for |up )?["']?([^"']+)["']?/i);
  if (searchMatch) {
    const searchQuery = searchMatch[1];

    try {
      const searchResponse = await fetch(`${req.url.replace('/api/chat', '/api/search')}`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ query: searchQuery }),
      });

      if (searchResponse.ok) {
        const { contextPrompt } = await searchResponse.json();
        searchContext = contextPrompt;
      }
    } catch (error) {
      console.error('Search integration error:', error);
    }
  }
}

// Create user message with attachments field
const userMessageRecord = await db.insert(message).values({
  conversationId,
  userId: session.user.id,
  content: userMessage,
  role: 'user',
  messageType: 'user',
  attachments: imageUrl ? [{ type: 'image', url: imageUrl }] : null, // Populate attachments JSONB field
}).returning();

// Build multimodal AI message array
const aiMessages = messages.map(m => {
  // For messages with image attachments, use multimodal format
  if (m.attachments && Array.isArray(m.attachments) && m.attachments.length > 0) {
    return {
      role: m.role,
      content: [
        { type: 'text', text: m.content },
        ...m.attachments.map(att => ({
          type: 'image_url',
          image_url: { url: att.url }
        }))
      ]
    };
  }
  // Standard text-only message
  return {
    role: m.role,
    content: m.content
  };
});

// Inject search context into system prompt
const systemPrompt = `You are a helpful AI assistant.

${searchContext ? `\n${searchContext}\n\nUse the search results above to inform your response.\n` : ''}

${existingContextFromPhase2}`;

// Send multimodal messages to AI model
const response = await openai.chat.completions.create({
  model: 'gpt-4-vision-preview', // or other multimodal model
  messages: [
    { role: 'system', content: systemPrompt },
    ...aiMessages
  ]
});
```

This wires imageUrl from MessageInput → message.attachments database field → multimodal AI request, enabling AI image analysis (INPUT-03).
  </action>
  <verify>
grep -A 60 "export function MessageInput" components/chat/message-input.tsx
grep "ImageUploader" components/chat/message-input.tsx
grep "search for.*toLowerCase" app/api/chat/route.ts
grep "searchContext" app/api/chat/route.ts
grep "attachments.*imageUrl" app/api/chat/route.ts
grep "image_url.*url" app/api/chat/route.ts
  </verify>
  <done>MessageInput with image upload, chat API with search intent detection, message.attachments population, and multimodal AI messages for image analysis</done>
</task>

</tasks>

<verification>
**Search integration verification:**
- [ ] searchWeb fetches DuckDuckGo API and parses results
- [ ] Search API route validates query length (min 3 chars)
- [ ] contextPrompt formatted for AI consumption
- [ ] Chat API detects search keywords and triggers search
- [ ] Search results injected into system prompt

**Image upload verification:**
- [ ] ImageUploader shows file picker on button click
- [ ] Client-side validation for type and size
- [ ] Preview displays before upload
- [ ] Upload button triggers uploadImage Server Action
- [ ] MessageInput accepts attached image
- [ ] Image URL passed with message on send

**Integration verification:**
- [ ] User can upload image → send message → image appears inline
- [ ] User says "search for React hooks" → AI searches → incorporates results
- [ ] Multiple images can be uploaded in conversation
- [ ] Image attachments stored in message.attachments JSONB field
</verification>

<success_criteria>
1. User clicks Add Image → selects PNG file → preview shows → uploads → image displays in chat
2. User types "search for latest TypeScript features" → AI searches DuckDuckGo → returns answer with sources
3. User uploads 15MB image → rejected with "File too large" error before upload
4. User uploads image and types question → both included in message → AI analyzes image
5. User sends message with "look up weather in Paris" → AI fetches search results → provides weather info
</success_criteria>

<output>
After completion, create `.planning/phases/05-resources-management-and-sharing/05-06-SUMMARY.md`
</output>
