---
phase: 02-ai-orchestration-intent-detection
plan: 04
type: execute
wave: 2
depends_on: [02-01]
files_modified:
  - lib/db/queries.ts
  - lib/ai/context-extractor.ts
  - app/api/chat/route.ts
  - lib/ai/prompts.ts
autonomous: true

must_haves:
  truths:
    - "Conversation context is extracted from messages automatically"
    - "Domain terms (technologies, tools, projects) are stored persistently"
    - "Context is retrieved and injected into system prompt at conversation start"
    - "User's terminology and preferences adapt over time"
    - "Context persists across browser sessions and days"
  artifacts:
    - path: "lib/ai/context-extractor.ts"
      provides: "Context extraction using AI to identify domain knowledge"
      exports: ["extractContext"]
    - path: "lib/db/queries.ts"
      provides: "Context storage and retrieval functions"
      exports: ["storeContext", "retrieveContext", "formatContextForPrompt"]
    - path: "app/api/chat/route.ts"
      provides: "Context loading and injection into streaming"
      contains: "retrieveContext"
  key_links:
    - from: "app/api/chat/route.ts"
      to: "lib/ai/context-extractor.ts"
      via: "extract context from conversation"
      pattern: "await extractContext"
    - from: "lib/ai/context-extractor.ts"
      to: "lib/db/queries.ts"
      via: "store extracted context"
      pattern: "await storeContext"
    - from: "app/api/chat/route.ts"
      to: "lib/db/queries.ts"
      via: "load context at conversation start"
      pattern: "await retrieveContext"
---

<objective>
Implement cross-session context memory that extracts domain knowledge from conversations and adapts to user's terminology over time.

Purpose: Enable AI to remember context across sessions (ORCH-06) and adapt to user's domain (ORCH-07). When user mentions "Kubernetes" on day 1 and returns day 2 saying "check the cluster", AI remembers the Kubernetes context.

Output: Context extraction system using AI to identify domain terms, storage in conversationContext table, retrieval and injection into system prompts.
</objective>

<execution_context>
@/Users/christian.baverstock/.claude/get-shit-done/workflows/execute-plan.md
@/Users/christian.baverstock/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-ai-orchestration-intent-detection/02-CONTEXT.md
@.planning/phases/02-ai-orchestration-intent-detection/02-RESEARCH.md
@.planning/phases/02-ai-orchestration-intent-detection/02-01-SUMMARY.md
@lib/db/schema.ts
@lib/db/queries.ts
@app/api/chat/route.ts
</context>

<tasks>

<task type="auto">
  <name>Implement context storage and retrieval queries</name>
  <files>lib/db/queries.ts</files>
  <action>
Add context management functions to lib/db/queries.ts (completing 02-01 database work):

1. **storeContext** - Save/update context entry:
```typescript
export async function storeContext(
  conversationId: string,
  contextType: 'domain' | 'preference' | 'project' | 'technology',
  contextKey: string,
  contextValue: any
) {
  return await db
    .insert(conversationContext)
    .values({
      conversationId,
      contextType,
      contextKey,
      contextValue,
    })
    .onConflictDoUpdate({
      target: [conversationContext.conversationId, conversationContext.contextKey],
      set: {
        contextValue,
        updatedAt: new Date(),
      },
    });
}
```

2. **retrieveContext** - Load all context for conversation:
```typescript
export async function retrieveContext(conversationId: string) {
  return await db
    .select()
    .from(conversationContext)
    .where(eq(conversationContext.conversationId, conversationId))
    .orderBy(desc(conversationContext.updatedAt));
}
```

3. **retrieveContextByType** - Filtered retrieval:
```typescript
export async function retrieveContextByType(
  conversationId: string,
  contextType: string
) {
  return await db
    .select()
    .from(conversationContext)
    .where(
      and(
        eq(conversationContext.conversationId, conversationId),
        eq(conversationContext.contextType, contextType)
      )
    )
    .orderBy(desc(conversationContext.updatedAt));
}
```

4. **formatContextForPrompt** - Convert context to string for system prompt injection:
```typescript
export async function formatContextForPrompt(conversationId: string): Promise<string> {
  const contexts = await retrieveContext(conversationId);

  if (contexts.length === 0) {
    return '';
  }

  const grouped = contexts.reduce((acc, ctx) => {
    if (!acc[ctx.contextType]) acc[ctx.contextType] = [];
    acc[ctx.contextType].push(`${ctx.contextKey}: ${JSON.stringify(ctx.contextValue)}`);
    return acc;
  }, {} as Record<string, string[]>);

  const sections = Object.entries(grouped).map(
    ([type, items]) => `${type.toUpperCase()}:\n${items.join('\n')}`
  );

  return `\n\nUSER CONTEXT:\n${sections.join('\n\n')}`;
}
```

Import necessary Drizzle operators (eq, and, desc). Follow existing query patterns from Phase 1.
  </action>
  <verify>Functions compile without errors, can be imported, TypeScript signatures match conversationContext schema</verify>
  <done>Context queries implemented with proper Drizzle ORM syntax, formatContextForPrompt returns prompt-ready string</done>
</task>

<task type="auto">
  <name>Create AI-powered context extraction</name>
  <files>lib/ai/context-extractor.ts</files>
  <action>
Create context extraction system using AI to identify domain knowledge (research Pattern 3 + Code Example):

```typescript
import { generateText, Output } from 'ai';
import { gemini } from '@/lib/ai/client';
import { z } from 'zod';
import { storeContext } from '@/lib/db/queries';

const contextExtractionSchema = z.object({
  contexts: z.array(
    z.object({
      key: z.string().describe('Context identifier (e.g., uses_kubernetes, prefers_typescript)'),
      value: z.any().describe('Context value (string, object, array)'),
      type: z.enum(['domain', 'preference', 'project', 'technology']),
      confidence: z.number().min(0).max(1),
    })
  ),
});

export async function extractContext(
  conversationId: string,
  messages: any[]
): Promise<void> {
  // Only extract from recent messages to avoid token limits
  // User decided ~10 messages context window
  const recentMessages = messages.slice(-10);

  const { output } = await generateText({
    model: gemini,
    messages: recentMessages,
    system: `Extract domain knowledge from this conversation:
- Technologies mentioned (Kubernetes, TypeScript, React, etc.)
- Tools being used (VS Code, Docker, AWS, etc.)
- Project details (names, domains, architectures)
- User preferences (coding style, deployment preferences)

Return structured context as key-value pairs.

Examples:
- "uses_kubernetes": { mentioned: true, version: "1.28", clusters: ["prod", "dev"] }
- "prefers_typescript": { strict: true, reason: "type safety" }
- "project_name": "acme-workflows"
- "tech_stack": ["Next.js", "PostgreSQL", "Vercel"]`,
    output: Output.object({
      schema: contextExtractionSchema,
    }),
  });

  // Store each extracted context
  for (const ctx of output.contexts) {
    // Only store high-confidence contexts (>0.7)
    if (ctx.confidence > 0.7) {
      await storeContext(conversationId, ctx.type, ctx.key, ctx.value);
    }
  }
}
```

Implementation notes:
- Uses structured output for reliable extraction
- Confidence threshold prevents false positives
- Processes last ~10 messages to respect token limits (user decision)
- Stores only meaningful, high-confidence context
- Follows research code example exactly
  </action>
  <verify>extractContext function compiles, can call generateText, stores contexts in database</verify>
  <done>Context extraction uses AI to identify domain terms, stores high-confidence contexts, processes last 10 messages per user requirements</done>
</task>

<task type="auto">
  <name>Integrate context into chat flow</name>
  <files>app/api/chat/route.ts, lib/ai/prompts.ts</files>
  <action>
Update chat API to load and inject context, plus extract context after responses:

1. **In app/api/chat/route.ts**, add context flow:

```typescript
// After conversation setup, before intent detection
const contextPrompt = await formatContextForPrompt(activeConversationId);

// In streamText call, append context to system prompt
const result = streamText({
  model: gemini,
  messages,
  system: systemPrompt + contextPrompt, // Inject context
  abortSignal: req.signal,
  async onFinish({ text }) {
    // Existing message saving logic...

    // Extract and store context from conversation
    try {
      await extractContext(activeConversationId, messages);
    } catch (error) {
      console.error('Context extraction failed:', error);
      // Don't fail the response if context extraction errors
    }
  },
});
```

2. **Update lib/ai/prompts.ts** with context-aware addendum:

Add to end of systemPrompt:
```typescript
export const systemPrompt = `...existing prompt...

When user context is available, use their terminology and remember their preferences:
- Reference technologies they use without re-explaining basics
- Adapt suggestions to their stack and tools
- Remember project names and details from previous messages`;
```

Flow:
1. Load context at conversation start
2. Inject into system prompt
3. AI responds with context awareness
4. Extract new context from conversation
5. Store for next session

This implements cross-session memory (ORCH-06) and domain adaptation (ORCH-07).
  </action>
  <verify>Chat API loads context before streaming, injects into system prompt, extracts after response, all without breaking existing chat functionality</verify>
  <done>Context memory system integrated into chat flow, AI receives user context in prompts, extracts and stores new context after responses, cross-session memory functional</done>
</task>

</tasks>

<verification>
After completion:
1. Start conversation, mention "Kubernetes" and "TypeScript"
2. Send a few messages, check conversationContext table has entries
3. Close browser, return later (or use different browser session)
4. Resume conversation, send "check my cluster" - AI should reference Kubernetes
5. Verify formatContextForPrompt output is readable and properly formatted
6. Check context confidence filtering works (only >0.7 stored)

**ORCH-05 Explicit Verification (remembers context from earlier in current conversation):**
7. In a single conversation session:
   - Message 1: "I'm deploying a React app to AWS"
   - Message 2-3: General questions about deployment
   - Message 4: "Should I use S3 for my app?" â†’ AI should recall React context from Message 1
   - Verify AI response references "React app" or demonstrates awareness of context from 3+ messages earlier
</verification>

<success_criteria>
- [x] Context extracted automatically from conversations using AI
- [x] Domain terms (technologies, tools, projects) stored in conversationContext table
- [x] Context retrieved and injected into system prompt at conversation start
- [x] AI adapts responses based on user's context (mentions Kubernetes when relevant)
- [x] Context persists across sessions (ORCH-06 requirement met)
- [x] High-confidence threshold (>0.7) prevents false positives
- [x] Last ~10 messages processed per user decision
- [x] ORCH-05 verified: AI recalls detail from message N when asked in message N+3 (explicit test in verification section)
</success_criteria>

<output>
After completion, create `.planning/phases/02-ai-orchestration-intent-detection/02-04-SUMMARY.md`
</output>
